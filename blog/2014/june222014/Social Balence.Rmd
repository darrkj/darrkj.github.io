---
title: "terrorblog"
author: "Kenny Darrell"
date: "June 16, 2014"
output: html_document
---


### Introduction

Many of my past blog post have been dependent on data that I have had to scrape from the web. I want to do a few things here. First I want to illustrate how easy this is to do if you find some data that you are interested in, I can now do this type of thing in about an hour. I also want to prep some data for another effort so this will be a good multi purpose demonstration. After my last blog about monads I want to rethink the procedure for how I build web crawler and scrapers. After looking back on a few different efforts of this same type I can see the same overall design so I want to see if I can refactor some patterns out of it, so I structured it a little differently that previous efforts.

First and foremost I want to emphasize that before starting down this path to examine the source to see if they have an easier way to provide the data, either an API or a direct download. Second make sure that they are okay ith you scaraping the data. If they allow you to scrape are there any constraints or permissions of use.

The source of interest is the [data](http://www.start.umd.edu/tops/).


Always turn stringsAsFactors to FALSE when doing this type of work or you will hit many walls where things appear to be easy but do not work. There are two main packages I use for thsi purpose, [httr](http://cran.fhcrc.org/web/packages/httr/index.html) and [XML](http://cran.fhcrc.org/web/packages/XML/index.html). It depends on how the data is structured as to which one is better to use. Here we will be using the httr package. We should alos load a few other packages as well as some utility code for the rest of this effort. Some of these functions in this gist are part of my refactoring attempts, can I get to some basic pattern for crawling and supply source specific functions for detail level.

```{r setup}
library(httr)
library(igraph)
library(d3Network)
library(devtools, warn.conflicts = F)
options(stringsAsFactors = FALSE)
source_gist('415e3308544ff2d77d4e')
```

### Getting the Data

Now we need to define our site of interest and actually crawl all of the links and scrape the data of interest. This basically results in one loop for each case, the first will gather all of the URLs we are interested in, while the second will pull data from each of these pages. 


```{r eval = FALSE}
# Base website
base <- 'http://www.start.umd.edu/tops/'
# Query string for alphabetical search
site <- 'terrorist_organizations_by_alpha.asp?q='

# These are the sites to search
site <- paste(base, site, LETTERS, sep = '')

# Initialze data frame.
group <- data.frame(ID = NA, name = NA)

for (i in site) {
  # Pull data for each letter.
  page <- cleanOrg(strsplit(as.character(GET(i)), '\n')[[1]])
  group <- rbind(group, page)
}
# Remove first inited row
group <- group[-1, ]

# Clean up workspace
rm(i, site, page)


# The scraping loop
details <- list()

for (i in 1:nrow(group)) {
  # Create url
  url <- paste(base, group[i, 1], sep = '')[1]

  x <- cleanDet(url)
  net <- x[[1]]
  x <- x[[2]]

  details[[group[i, 2]]] <- list(name = group[i, 2], ID = group[i, 1], 
                                 net = net
}

# clean up
rm(group, base, url, i, x, cleanDet, cleanOrg, net)
```

```{r echo = FALSE}
load("~/Desktop/gblog/terror.RData")
rm(cleanDet, cleanOrg)
```
Now we have all of the information each terrorist oraginzation. We need to do some cleanup and create a network structure in the process.

### Cleaning The Data


```{r}
# Initialze the network edge list
net <- data.frame(from = NA, fromn = NA, to = NA, ton = NA, type = NA)

# Loop through all o fhte detail info and pull out individual edges
for (i in seq(details)) {
  cur <- details[[i]]
  # Get the ID (4324) for the current org
  cur$ID <- ID(cur$ID)

  # Add the ID to the edge list
  if (!is.null(cur$net$ID)) {
    cur$net$from <- cur$ID 
    cur$net$fromn <- cur$name
    cur$net$to <- ID(cur$net$ID)
  
    # Clean up the edge list, add name connection type
    tmp <- strsplit(cur$net$name, ' -- ')
    cur$net$ton <- unlist(lapply(tmp, `[`, 1))
    cur$net$type <- unlist(lapply(tmp, `[`, 2))
    # remove original fields
    cur$net <- cur$net[, 3:7]
    net <- rbind(net, cur$net)
  } 
}
net <- net[-1, ]
#

```

```{r}
rm(cur, i, tmp, ID, clean)

# Turn suspected allys into allies
ally <- c("Ally", 'Ally (Suspected)', 'Armed Wing', 'Founding Group', 
          'Founding Group (Suspected)', 'Founding Group and Faction', 
          'General Command (PFLP-GC)', "Political Wing", 'Successor', 
          'Suspected Alias/Ally', "Shared Members", 'Other Affiliation', 
          'Supported Cause', 'Umbrella Organization',
          "Umbrella Organization (Suspected)", "Other Affiliation")


enemy <- c("Competing Faction", "Enemy", "Faction", "Rival", 
           "Rival and Ally", "Splinter Group",
           "Splinter Group (Suspected)") 

net$conn <- ifelse(net$type %in% ally, 1, -1)

```


Here is what are out network looks like.
```{r, eval = F}
x <- graph.data.frame(net[, c(2, 4)])
d3plot(x, 700, 1300)
```

### Social Balance Analysis


```{r}
# For social balance each edge in a triangle must add to an even number.
nodes <- unique(net$from)

tri <- data.frame(n1 = NA, n2 = NA, n3 = NA)

for (i in nodes) {
  n2 <- net[net$from == i, ]$to
  if ( length(n2) > 1) {
    for (j in n2) {
      n3 <- net[net$from == j, ]$to
      n <- intersect(n2, n3)
      if ( length(n) > 0 ) {
        tri <- rbind(tri, data.frame(n1 = i, n2 = j, n3 = n))
      }
    }
  }
}
tri <- tri[-1, ]



SocImbal <- data.frame(tri = NA, fromn = NA, ton = NA, type = NA, conn = NA, prod = NA)

for(i in 1:nrow(tri)) {
  a <- net[net$from == tri[i, 1] & net$to == tri[i, 2, ], c(2, 4:6)]
  b <- net[net$from == tri[i, 1] & net$to == tri[i, 3, ], c(2, 4:6)]
  c <- net[net$from == tri[i, 2] & net$to == tri[i, 3, ], c(2, 4:6)]
  
  prod <- a$conn * b$conn * c$conn
  if (prod < 0) {
    SocImbal <- rbind(SocImbal, 
                      data.frame(tri = i, a, prod),
                      data.frame(tri = i, b, prod),
                      data.frame(tri = i, c, prod))
  }
}

SocImbal <- SocImbal[-1, ]

SocImbal$color <- ifelse(SocImbal$conn == 1, 'blue', 'red')

```



```{r}
Imbal <- unique(SocImbal$tri)
length(Imbal)
for (i in Imbal[1:4]) {
  x <- SocImbal[SocImbal$tri == i, c(2, 3, 4, 7)]
  y <- graph.data.frame(x[, 1:2])
  E(y)$label <- x$type
  plot(y, edge.color = x$color)
}
```




