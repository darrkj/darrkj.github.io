<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Packages</title>



    <link rel="stylesheet" type="text/css" href="../../../stylesheets/blog.css">
<!-- Styles for R syntax highlighter -->
    <link rel="stylesheet" type="text/css" href="../../../stylesheets/blog2.css">
    <link rel="stylesheet" type="text/css" href="../../../stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="../../../stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="../../../stylesheets/print.css" media="print" />
<!-- R syntax highlighter -->
    <script src="../../../javascripts/r.js"></script>


</head>

<body>

<div class="container">


    <header>
      <div class="container">
        <a href="http://darrkj.github.io/blogs" class="btn">Blogs</a>
        <h1>Interesting R Packages</h1>
        <h2></h2>

<h4 class="author"><em>Kenny Darrell</em></h4>
<h4 class="date"><em>August 23, 2014</em></h4>
        </section>
      </div>
    </header>





<div id="background" class="section level2">
<h2>Background</h2>
<p>There are now <a href="http://www.r-bloggers.com/milestone-7000-packages-on-cran/">tons</a> of packages on CRAN, and many more on github. After attending the <a href='http://user2015.math.aau.dk/'>useR! Conference</a> I noticed that a lot of this growth is in width instead of depth, they are doing more than should statistical analysis. There seems to be a growing number of computer scientists and software engineers adding packages and even making new versions of R. A similar thing happened to Javascript about ten years ago. Google and Mozilla had a <a href="https://en.wikipedia.org/wiki/JavaScript_engine#The_JavaScript_engine_race:_2008_and_2009">battle</a> over which browser was faster, which really meant who had a faster Javascript implementation. In the end Javascript was the winner as it became really fast. R seems to be in a similar position. <a href="http://blogs.technet.com/b/machinelearning/archive/2015/04/06/microsoft-closes-acquisition-of-revolution-analytics.aspx">Microsoft purchased Revolution Analytics</a> so that they can put R inside of things like <a href="http://blog.revolutionanalytics.com/2015/05/r-in-sql-server.html">SQL Server</a>, Azure and Excel. Oracle is pushing <a href="http://www.oracle.com/technetwork/database/database-technologies/r/r-distribution/overview/index.html">one version</a> into the Oracle database so you can run analytics from SQL code while also <a href="https://labs.oracle.com/pls/apex/f?p=labs:49:::::P49_PROJECT_ID:131">creating another implementation</a> that compiles to jvm bytecode. <a href="http://blog.revolutionanalytics.com/2014/07/dsc-2014.html">There</a> <a href="http://4dpiecharts.com/2013/07/16/how-r-will-turn-into-sql/">is</a> <a href="http://4dpiecharts.com/2013/09/07/fearsome-engines-part-1/">also</a> <a href="http://4dpiecharts.com/2013/10/13/fearsome-engines-part-2-innovations-and-new-features/">a</a> <a href="http://4dpiecharts.com/2013/10/13/fearsome-engines-part-3-which-one-should-you-use/">whole</a> <a href="https://dynamicecology.wordpress.com/2014/01/14/r-isnt-just-r-anymore/">slew</a> <a href="https://radfordneal.wordpress.com/">of</a> <a href="http://www.mango-solutions.com/wp/products-services/products/validr/">various</a> <a href="http://www.renjin.org/">other</a> <a href="http://www.cs.kent.ac.uk/projects/cxxr/">implemetnations</a> <a href="https://github.com/jtalbot/riposte">and</a> <a href="http://spotfire.tibco.com/discover-spotfire/what-does-spotfire-do/predictive-analytics/tibco-enterprise-runtime-for-r-terr">work</a> <a href="https://github.com/allr/purdue-fastr">happening</a>. This could raise the bar for all of R as they each start to compete. It may also give rise to a <a href="https://en.wikipedia.org/wiki/Programming_language_specification">formal specification</a> which it <a href="http://r.cs.purdue.edu/pub/ecoop12.pdf">lacks</a> now as the GNU implementation is the spec.</p>
<p>I think in general that when a bunch of people complain that something is slow or that it is not really high-quality enough that it is likely to become so. This rings even more true when you consider quotes like, <a href="http://www.goodreads.com/quotes/226225-there-are-only-two-kinds-of-languages-the-ones-people">"There are only two kinds of languages: the ones people complain about and the ones nobody uses"</a>, Bjarne Stroustrup. A long time ago people complained that <a href="https://www.cs.utah.edu/~elb/folklore/mel.html">assembly was to high level</a> and you should use machine code. Then the debate moved to c and fortran being toys and that <a href="http://www.urbandictionary.com/define.php?term=real+programmer&amp;defid=1734951">real programmers</a> used assembly language to get work done. Now most people see these two languages as basically being a cleaner assembly. Later many people poked fun at <a href="http://programmers.stackexchange.com/questions/368/why-do-people-still-say-java-is-slow">Java for being to slow</a> to do anything real. That has changed quite a bit, the jvm and the hotspot compiler are probably two of the most well tuned peices of software in existence, and they are lighting fast. Javascript was supposedly once only used to add random stuff to your Myspace page, but it got its drastic makeover. Thus maybe its good that so many people say that R canâ€™t be used in production, it can only work on small data, it is slow, or it is single core. The part about small data is interesting as well, people often claim that it can only work on data in RAM, I am curious to what tools these people use that are capable of doing work to data on disk that is not in RAM. I know what they mean but the statement is misleading, and they are not really correct either. You can pull data into RAM and stream through it, it just does not ahpen by default. Lisp did not have an object system but most real users of lisp did not care, you could build your own, in fact I have <a href="https://twitter.com/p_balduino/status/527885335544754178">heard</a> that it was a homework assignment in some sopmore MIT courses while to do that in C took a really smart guy a few years. If you want this in R and are competant you could put together a solution for your case with not much worry.</p>
<p>Having used R for around 7 years and seeing the growing push from other environments I was curious if the platform would continue being as great as it has been as things continue to change.</p>
<p>A few reasons for this are the growing push for data centric tools in languages like Python which already has a great ecosystem and tooling for things such as testing/etc. Newer languages Julia are growing in there capabilities. Things like Spark/Scala allow you to scale more easily.</p>
<p>A few years back this seemed like what happened to SAS and SPSS, they became less relavent because they could not keep up with reading from new data sources, and having all the newer algorithms. They were not easy to use in production, sure you could use things to make them write to a database but that seems like bolting onto an older way of doing things. So a lot of our work as shifted to using R in a client domain. Was this one step with the next to be into something like spark/scala?</p>
<p>As data science becomes more central to organizations places require more from the tools in this area. From what I saw the R community is very much interested in this area. There were a few talks about testing. a few about using R in production, a few about new R engines and many more about reproducibility. These are the things it needs to be more competitive with alternatives. This was a sign that it is at least aware of its gaps and people are trying to make fixes.</p>
<p>Another thing that was really interesting. In the past there have usually been around 200 to 300 participants. This year was just over 700. Historically there were a large number of open source contributor/hobbyists and mostly academics. Most of the new surge was from industry and a fair amount of government. Many of these are companies that are very similar to ours, one for instance called Data Robot, which is about two years old. Given the very tech savvy nature of the audience I could get anybody to talk about there business strategy, how they work, etc. Learned a lot here, main interest point was from DataRobot. There approach to to creating software and incorporating lessons learned into that ecosystem from every new project was really interesting. They value similar things like target shuffling but the first time they get bit by this they add it into there product. There product is not a product in the sense of something like SAS but more like a collection of code that has lots of wrappers and APIs. Almost like aardvark but with more modeling code and wrappers around things like scikit learn and random forests in R. There were also a lot of companies that that worked in smaller industries, like advertise</p>

<h2>assertr</h2>

<p>I wanted to talk about some tools that I think are really cool and will help R become more capable. The first is the <a href="https://cran.r-project.org/web/packages/assertr/vignettes/assertr.html">assertr</a> package. It is useful for doing assertions on data, checking that your data is what you think it is.</p>

<pre class="r"><code>library(lubridate)
library(dplyr)
library(assertr)</code></pre>

<p>We can start by using the verify function. For the mtcars dataset, I know that the mpg field should be positive, which it is.</p>
<pre class="r"><code>mtcars %&gt;% verify(mpg &gt;= 0) %&gt;% head</code></pre>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
<p>What if this was not true. We can modify the data demonstarte what would happen.</p>
<pre class="r"><code>mtcars_bad &lt;- mtcars
mtcars_bad$mpg[1] &lt;- -1

mtcars_bad %&gt;% verify(mpg &gt;= 0)</code></pre>

<pre><code>## Error in verify(., mpg &gt;= 0) : verification failed! (1 failure)</code></pre>


<p>There is another function called assert. To use this we give a function, that is really a predicate function, and data instead of an expression.</p>
<pre class="r"><code>mtcars %&gt;% assert(within_bounds(0, Inf), mpg) %&gt;% head</code></pre>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>

<pre class="r"><code>mtcars_bad %&gt;% assert(within_bounds(0, Inf), mpg) %&gt;% head</code></pre>

<pre><code>## Error: Vector 'mpg' violates assertion 'within_bounds' 1 time (value [-1] at index 1)</code></pre>
<p>One cool thing to note here is that this shows the actual row that caused this issue, verufy just said that there was an issue.</p>
<p>We can also look at things from a macro level, the whole data set instead of each specific value.</p>
<pre class="r"><code>mtcars %&gt;% verify(nrow(.) &gt; 10) %&gt;% head</code></pre>
<pre><code>##                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1</code></pre>
<p>Another cool feature is the ability to create custom predicate functions.</p>
<pre class="r"><code># Add a character field.
mtcars$string &lt;- sample(LETTERS, nrow(mtcars), replace = T)
# Create predicate function.
not.empty.p &lt;- function(x) if (x == &quot;&quot;) FALSE
# Check it
mtcars %&gt;% assert(not.empty.p, string) %&gt;% head</code></pre>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb string
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4      P
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4      D
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1      V
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1      F
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2      U
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1      W</code></pre>
<pre class="r"><code># Make one of them empty
mtcars$string[1] &lt;- ''
mtcars %&gt;% assert(not.empty.p, string) %&gt;% head</code></pre>

<pre><code>## Error: Vector 'string' violates assertion 'not.empty.p' 1 time (value [] at index 1)</code></pre>
<p>The last thing I want to note here is the insist function. It is often the case that when you start to push some analysis out of the exploratory mode you need to verify that the data looks similar to what it did originally. One thing you need to check for is outliers. The insist can help with this.</p>

<pre class="r"><code>mtcars %&gt;%
  insist(within_n_sds(3), mpg) %&gt;%
  group_by(cyl) %&gt;%
  summarise(avg.mpg=mean(mpg))</code></pre>

<pre><code>## Source: local data frame [3 x 2]
## 
##     cyl  avg.mpg
##   (dbl)    (dbl)
## 1     4 26.66364
## 2     6 19.74286
## 3     8 15.10000</code></pre>
<pre class="r"><code>mtcars %&gt;%
  insist(within_n_sds(2), mpg) %&gt;%
  group_by(cyl) %&gt;%
  summarise(avg.mpg=mean(mpg))</code></pre>

<pre><code>## Error: Vector 'mpg' violates assertion 'within_n_sds' 2 times (e.g. [32.4] at index 18)</code></pre>
<p>There are many other cool things build into this pacakge which can be see at the link above. This is not the only package that attempts to provide this type of functionality. There is some discussion of this <a href="http://www.r-bloggers.com/the-state-of-assertions-in-r/">here</a>.</p>
<p>There are other packages that do are providing similar functionality through different means and some have different functionality altogether. The <a href="http://www.r-bloggers.com/be-assertive/">assertive</a> package has a large collection of <code>assert_all_are_?</code> and <code>is_in_?</code> types of functions that can be used in a manner seen below.</p>

<h2>assertive</h2>

<pre class="r"><code>library(assertive)
is_in_future(x = today() + days(10))</code></pre>
<pre><code>## 2015-09-08 20:00:00 
##                TRUE</code></pre>
<pre class="r"><code>is_in_future(x = today() - days(10))</code></pre>

<pre><code>## There was 1 failure:
##   Position               Value   Cause
## 1        1 2015-08-19 20:00:00 in past</code></pre>

<p>The first think to note here is that this does not cause error. It says that there was one failure instead.</p>


<h2>assertthat</h2>


<p>There is also <a href="https://github.com/hadley/assertthat">assertthat</a> which seems to be more for functions than data.</p>
<pre class="r"><code>library(assertthat)

is_odd &lt;- function(x) {
  assert_that(is.numeric(x), length(x) == 1)
  x %% 2 == 1
}</code></pre>
<pre class="r"><code>assert_that(is_odd(2))</code></pre>

<pre><code>## Error: is_odd(x = 2) is not TRUE</code></pre>
<pre class="r"><code>on_failure(is_odd) &lt;- function(call, env) {
  paste0(deparse(call$x), &quot; is even&quot;)
}
assert_that(is_odd(1))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>assert_that(is_odd(2))</code></pre>

<pre><code>## Error: 2 is even</code></pre>

<h2>argufy</h2>

<p>A package that provides some assertions on the arguemnts of functions <a href="https://github.com/gaborcsardi/argufy">argufy</a> is an interesting idea as well.</p>
<pre class="r"><code>library(argufy)
prefix &lt;- argufy(function(
 str =     ? is.character,
 len =     ? is.numeric(len) &amp;&amp; len &gt; 0) {
  substring(str, 1, len)
})

substring('This works', 1, 5)</code></pre>
<pre><code>## [1] &quot;This &quot;</code></pre>
<pre class="r"><code>prefix('This works', 5)</code></pre>
<pre><code>## [1] &quot;This &quot;</code></pre>
<pre class="r"><code>substring('This works', 1, -1)</code></pre>
<pre><code>## [1] &quot;&quot;</code></pre>
<pre class="r"><code>prefix('This dos not work', -1)
# Error in is.numeric &amp;&amp; len &gt; 0 : invalid 'x' type in 'x &amp;&amp; y'</code></pre>

<h2>ensurer</h2>

<p>The <a href="https://github.com/smbache/ensurer">ensurer</a> package.</p>
<pre class="r"><code>library(ensurer)
matrix(runif(16), 4, 4) %&gt;%
  ensure_that(ncol(.) == nrow(.), all(. &lt;= 1))</code></pre>
<pre><code>##           [,1]        [,2]      [,3]      [,4]
## [1,] 0.7939310 0.101298372 0.6966813 0.4942526
## [2,] 0.5289590 0.935170193 0.6730220 0.4995462
## [3,] 0.3428521 0.003302559 0.4415779 0.3875924
## [4,] 0.8808607 0.054348952 0.4190798 0.3552488</code></pre>
<pre class="r"><code>matrix(runif(20), 5, 4) %&gt;%
  ensure_that(ncol(.) == nrow(.), all(. &lt;= 1))</code></pre>

<pre><code>## Error: conditions failed for call 'matrix(runif(20), 5 ..  nrow(.), 
##   all(. &lt;= ': * ncol(.) == nrow(.)</code></pre>

<h2>immutequality</h2>


<p>While looking into the ensurer package above I noticed a few other packages on <a href="https://github.com/smbache">smbache's</a> github page. The provide some interesting capabilities ad even intresting restrictions.</p>

<p><a href="https://github.com/smbache/immutequality">immutequality</a> It seems to work just like var and val in Scala.</p>
<pre class="r"><code>library(immutequality)
x = 10

print(x)</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code># Will raise an error!
x &lt;- x*2</code></pre>
<pre><code>## Error: Cannot reuse the symbol x!</code></pre>
<pre class="r"><code># This also
assign(&quot;x&quot;, 20)</code></pre>
<pre><code>## Error: Cannot reuse the symbol x!</code></pre>
<pre class="r"><code># .. and this too
x = 20</code></pre>
<pre><code>## Error: Cannot reuse the symbol x!</code></pre>
<pre class="r"><code># But this works.

y &lt;- 5

y &lt;- y + 1</code></pre>

<h2>import</h2>


<p><a href="https://github.com/smbache/import">import</a> Say I needed to use the mdy function from lubridate. In order to have access to it I need to load the the lubridate library. THis pulls a lot of other stuff into the workspace. If I need one function from a large number of packages I can very quickly add a lot of bloat, I can also hide things that I want. There are some issues with plyr and dplyr doing this. Sometimes I need somthing like the ddply type of function but I almost always have dplyr loaded. One solution is to know the correct order to load them, which may not always have a valid answer. THe other option is to use something like lubridate::mdy. An even more precise solution is to use the import package.</p>

<pre class="r"><code>head(objects(&quot;package:lubridate&quot;))</code></pre>
<pre><code>## [1] &quot;%--%&quot;        &quot;%m-%&quot;        &quot;%m+%&quot;        &quot;%within%&quot;    &quot;am&quot;         
## [6] &quot;as.difftime&quot;</code></pre>
<pre class="r"><code>length(objects(&quot;package:lubridate&quot;))</code></pre>
<pre><code>## [1] 157</code></pre>
<pre class="r"><code># Notice how the package follows wants you to follow its own advice. 
library(import)</code></pre>
<pre><code>## The import package should not be attached.
## Use &quot;colon syntax&quot; instead, e.g. import::from, or import:::from.
## 
## Attaching package: 'import'
## 
## The following object is masked from 'package:lubridate':
## 
##     here</code></pre>

<p>Instead we should use it like this.</p>

<pre class="r"><code>import::from(magrittr, &quot;%&gt;%&quot;, &quot;%$%&quot;, .into = &quot;operators&quot;) 
import::from(lubridate, mdy, .into = &quot;datatools&quot;)

import::into(&quot;operators&quot;, &quot;%&gt;%&quot;, &quot;%$%&quot;, .from = magrittr)
import::into(&quot;datatools&quot;, arrange, .from = dplyr)
</code></pre>

<pre class="r"><code>source_url('https://raw.githubusercontent.com/darrkj/home/gh-pages/rcode/import.R')
import('igraph_2_d3')
import('d3plot')</code></pre>





<p>I have done somethng similar to this before in some of my posts and it looked like this. This had some advantages over just including all of the code but has the same disadvantages talked about in the reasoning link.</p>

<p>This package also provides something similar to python style modules.</p>
</code></pre>import::from(some_module.R, a, b, p, plot_it)</code></pre>

<h2>modules</h2>

<p>Instead of digging into this though I want to talk about a package the documentation referred to.</p>

<p>The<a href="https://github.com/klmr/modules">modules</a> package replicates the python module methodolgy. The is great documentation about the reasoning behind this <a href="https://github.com/klmr/modules/wiki/Design-rationale">here</a> and a comparison <a href="https://github.com/klmr/modules/wiki/Feature-comparison">here</a>.</p>






<p>Most of this gives us some of the useful features I like in Scala and Python.</p>


<h2>wakefield</h2>

<p>Another really cool is <a href="https://trinkerrstuff.wordpress.com/2015/04/30/wakefield-random-data-set-part-ii/">wakefield</a></p>
<pre class="r"><code>#if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;); library(pacman)
#p_install_gh(&quot;trinker/wakefield&quot;)
#p_load(dplyr, wakefield)

library(wakefield)
#set.seed(10)
 
r_data_frame(n = 30,
    id,
    race,
    age(x = 8:14),
    Gender = sex,
    Time = hour,
    iq,
    grade, 
    height(mean=50, sd = 10),
    died,
    Scoring = rnorm,
    Smoker = valid
)</code></pre>
<pre><code>## Source: local data frame [30 x 11]
## 
##       ID      Race   Age Gender     Time    IQ Grade Height  Died
##    (chr)    (fctr) (int) (fctr)   (tims) (dbl) (dbl)  (dbl) (lgl)
## 1     01     White    14 Female 00:30:00    98  88.6     46 FALSE
## 2     02 Bi-Racial    12   Male 00:30:00   101  79.1     63 FALSE
## 3     03     White    13   Male 02:30:00   107  91.4     55 FALSE
## 4     04     White    12   Male 03:30:00   112  88.5     56  TRUE
## 5     05     White    12 Female 04:00:00    82  88.8     57  TRUE
## 6     06     White    11   Male 04:00:00    91  85.2     45 FALSE
## 7     07     White    10 Female 04:00:00   100  86.3     56 FALSE
## 8     08     White    10 Female 04:30:00   106  90.9     55 FALSE
## 9     09  Hispanic    13 Female 04:30:00   101  90.9     46  TRUE
## 10    10     White    11   Male 05:00:00    84  88.1     55 FALSE
## ..   ...       ...   ...    ...      ...   ...   ...    ...   ...
## Variables not shown: Scoring (dbl), Smoker (lgl)</code></pre>


<h2>daff</h2>

<p>A very hard problem is the versioning of data. It would be great if things like git could handle data, they can handle smaller data sets. The <a href="https://github.com/edwindj/daff">daff</a> package, which is a wrapper around a<a href="https://github.com/paulfitz/daff">Java library</a> provides some functionality in this area.</p>

<pre class="r"><code>library(daff)
y &lt;- iris[1:3,]
z &lt;- y

z &lt;- head(z, 2) # remove a row
z[1,1] &lt;- 10 # change a value
z$hello &lt;- &quot;world&quot;  # add a column
z$Species &lt;- NULL # remove a column

patch &lt;- diff_data(y, z)
render_diff(patch)</code></pre>

<div style="text-align:center;"> <iframe src="http://darrkj.github.io/blog/2015/aug232015/daff.html" width="580" height="140" style="background-color: Snow"></iframe></div>

<p>You can see how a data.frame is different from another. This allows you to do some cool things. You can patch once source with the difference so that it is up to date. It also lets you resolve issues of two sources sharing a common data set but have deviated in differnet ways. You can merge both copies with the parent to get all updates. There are some examples of this on the github site.</p>



</div>






<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with --self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

